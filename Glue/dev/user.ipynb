{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b53fa676-a30f-413c-a8fb-51388f21344b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.15\n",
      "pip 22.3.1 from /home/glue_user/.local/lib/python3.7/site-packages/pip (python 3.7)\n"
     ]
    }
   ],
   "source": [
    "! python3 --version\n",
    "! pip3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a3e7646-f4ba-4719-a596-7ede64cf7c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting mysql-connector-python\n",
      "  Downloading mysql_connector_python-8.0.32-cp37-cp37m-manylinux1_x86_64.whl (23.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<=3.20.3,>=3.11.0\n",
      "  Downloading protobuf-3.20.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf, mysql-connector-python\n",
      "Successfully installed mysql-connector-python-8.0.32 protobuf-3.20.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fa9bd81-9ced-41d1-aa56-a111def6d66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME=\"Amazon Linux\"\n",
      "VERSION=\"2\"\n",
      "ID=\"amzn\"\n",
      "ID_LIKE=\"centos rhel fedora\"\n",
      "VERSION_ID=\"2\"\n",
      "PRETTY_NAME=\"Amazon Linux 2\"\n",
      "ANSI_COLOR=\"0;33\"\n",
      "CPE_NAME=\"cpe:2.3:o:amazon:amazon_linux:2\"\n",
      "HOME_URL=\"https://amazonlinux.com/\"\n"
     ]
    }
   ],
   "source": [
    "! cat /etc/os-release\n",
    "! cp ./mysql-connector-java-5.1.49.jar $SPARK_HOME/jars\n",
    "! ls $SPARK_HOME/jars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab1f2ff6-d455-4591-a389-822cd22286e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import boto3\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import col, lit, concat, create_map\n",
    "from pyspark.sql.types import StringType\n",
    "from itertools import chain\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "\n",
    "import csv, io\n",
    "import mysql.connector\n",
    "from functools import partial\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c97b7c5-561e-4325-904b-d16c29800a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "           .appName('123.com') \\\n",
    "           .config(\"spark.jars\", \"mysql-connector-java-5.1.49.jar\") \\\n",
    "           .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20de2989-eb74-4af8-9c4e-6064ff8e162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DB_Connection():\n",
    "    def __init__(self, db_name, hostname = None, user = None, password = None, driver_type = \"mysql\", driver_port = 3306, glue_cilent = None, connection_name = None):\n",
    "        try:\n",
    "            self.glue = False\n",
    "            if glue_cilent is not None and connection_name is not None:\n",
    "                self.glue = True\n",
    "                connection = glue_cilent.get_connection(Name=connection_name)\n",
    "                self.hostname = connection['Connection']['ConnectionProperties']['JDBC_CONNECTION_URL']\n",
    "                self.hostname = self.hostname.split('/')[2].split(':')[0]\n",
    "                self.user = connection['Connection']['ConnectionProperties']['USERNAME']\n",
    "                self.password = connection['Connection']['ConnectionProperties']['PASSWORD']\n",
    "            else:\n",
    "                self.hostname = hostname\n",
    "                self.user = user\n",
    "                self.password = password\n",
    "            \n",
    "            self.conn = None\n",
    "            self.db_name = db_name\n",
    "            self.driver_type = driver_type\n",
    "            self.driver_port = driver_port\n",
    "            \n",
    "            self.jdbc_url = f'jdbc:{self.driver_type}://{self.hostname}:{self.driver_port}/{self.db_name}'\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting connection settings for DB: {db_name} at {hostname}\\n{e}\")\n",
    "    def get_options(self, table):\n",
    "        return {'url': self.jdbc_url,'user': self.user, 'password': self.password, 'dbtable': table}\n",
    "    def get_conn(self, dbType = \"mysql\", mandatory = False, ssl_disabled= True):\n",
    "        # self.conn.is_connected()\n",
    "        if dbType == \"mysql\":\n",
    "            self.conn =  mysql.connector.connect(user=self.user, password=self.password, host=self.hostname, database=self.db_name, ssl_disabled= ssl_disabled)\n",
    "        if mandatory: assert self.conn is not None, f\"Did not manage to connect to {dbType}\"\n",
    "        return self.conn\n",
    "    def close_conn(self):\n",
    "        if self.conn is not None and self.conn.is_connected():\n",
    "            self.conn.close()\n",
    "\n",
    "def write_to_csv(output, filename):\n",
    "    output = output.getvalue().split('\\r\\n')[:-1]\n",
    "    if len(output) > 0:\n",
    "        # print(output)\n",
    "        output = [x.split(',') for x in output]\n",
    "        with open(filename, 'w') as out_file:\n",
    "            writer = csv.writer(out_file, delimiter =\",\")\n",
    "            writer.writerows(output)\n",
    "\n",
    "def db1_customer_f_partition(partitionData, db1, bucket = None, outputfolder = None):\n",
    "    output = io.StringIO()\n",
    "    errorExist = False\n",
    "    for row in partitionData:\n",
    "        if db1.conn is None or not db1.conn.is_connected():\n",
    "            db1.get_conn(dbType = 'mysql')\n",
    "        db1_cursor = db1.conn.cursor()\n",
    "        \n",
    "        row = row.asDict()\n",
    "        try: # %(emp_no)s\n",
    "            mapping = {'customer_id': row['id'], 'email': row['email'], 'tenant': row['TENANT']}\n",
    "            db1_cursor.execute(\"\"\"\n",
    "                INSERT INTO customer(customer_id, email, tenant) \n",
    "                VALUES (%(customer_id)s,%(email)s,%(tenant)s) \n",
    "                ON DUPLICATE KEY UPDATE email = %(email)s;\"\"\" \n",
    "                , mapping)\n",
    "            db1.conn.commit()\n",
    "            # csv.DictWriter(output, row.keys()).writerow(row)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            errorExist = True\n",
    "            csv.DictWriter(output, row.keys()).writerow(row)\n",
    "        # yield Row(**row)\n",
    "    db1.close_conn()\n",
    "    if errorExist:\n",
    "        print( outputfolder + 'card_customer_error.csv')\n",
    "        write_to_csv(output, 'error1.csv') # local testing\n",
    "#         s3_resource = boto3.resource('s3')\n",
    "#         s3_resource.Object(bucket, outputfolder + 'card_customer_error.csv').put(Body=output.getvalue())\n",
    "    print(\"DONE - db1_customer_f_partition\")\n",
    "\n",
    "def db1_card_f_partition(partitionData, db1, bucket = None, outputfolder = None):\n",
    "    output = io.StringIO()\n",
    "    errorExist = False\n",
    "    for row in partitionData:\n",
    "        if db1.conn is None or not db1.conn.is_connected():\n",
    "            db1.get_conn(dbType = 'mysql')\n",
    "        db1_cursor = db1.conn.cursor()\n",
    "        \n",
    "        row = row.asDict()\n",
    "        try: # %(emp_no)s\n",
    "            mapping = {'CARD_ID': row['card_id'], 'CARD_TYPE': row['card_type'], 'REWARD_TYPE': row['REWARD_TYPE'], 'TENANT': row['TENANT'], 'CUSTOMER_ID': row['id']}\n",
    "            db1_cursor.execute(\"\"\"\n",
    "                INSERT INTO card(card_id, card_type, reward_type, tenant, customer_id) \n",
    "                VALUES (%(CARD_ID)s,%(CARD_TYPE)s,%(REWARD_TYPE)s,%(TENANT)s,%(CUSTOMER_ID)s) \n",
    "                ON DUPLICATE KEY UPDATE card_type = %(CARD_TYPE)s, reward_type = %(REWARD_TYPE)s, customer_id = %(CUSTOMER_ID)s;\"\"\" \n",
    "                , mapping)\n",
    "            db1.conn.commit()\n",
    "            # csv.DictWriter(output, row.keys()).writerow(row)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            errorExist = True\n",
    "            csv.DictWriter(output, row.keys()).writerow(row)\n",
    "        # yield Row(**row)\n",
    "    db1.close_conn()\n",
    "    if errorExist:\n",
    "        write_to_csv(output, 'error1.csv') # local testing\n",
    "        print(outputfolder + 'card_card_error.csv')\n",
    "#         s3_resource = boto3.resource('s3')\n",
    "#         s3_resource.Object(bucket, outputfolder + 'card_card_error.csv').put(Body=output.getvalue())\n",
    "    print(\"DONE - db1_card_f_partition\")\n",
    "\n",
    "def db2_cardtype_f_partition(partitionData, db1, bucket = None, outputfolder = None):\n",
    "    output = io.StringIO()\n",
    "    errorExist = False\n",
    "    for row in partitionData:\n",
    "        if db1.conn is None or not db1.conn.is_connected():\n",
    "            db1.get_conn(dbType = 'mysql')\n",
    "        db1_cursor = db1.conn.cursor(buffered=True)\n",
    "        \n",
    "        row = row.asDict()\n",
    "        try: # %(emp_no)s\n",
    "            mapping = {'card_type': row['card_type'], 'tenant': row['TENANT']}\n",
    "            db1_cursor.execute(\"\"\"SELECT * FROM card_type where name=%(card_type)s AND tenant=%(tenant)s \"\"\", mapping)\n",
    "            if db1_cursor.rowcount > 0 :\n",
    "                db1_cursor.execute(\"\"\"UPDATE card_type SET name=%(card_type)s , tenant=%(tenant)s WHERE name=%(card_type)s AND tenant=%(tenant)s\"\"\", mapping)\n",
    "            else:\n",
    "                db1_cursor.execute(\"\"\"INSERT INTO card_type (name,tenant) VALUES (%(card_type)s , %(tenant)s )\"\"\", mapping )\n",
    "            db1.conn.commit()\n",
    "            # csv.DictWriter(output, row.keys()).writerow(row)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            errorExist = True\n",
    "            csv.DictWriter(output, row.keys()).writerow(row)\n",
    "        # yield Row(**row)\n",
    "    db1.close_conn()\n",
    "    if errorExist:\n",
    "        write_to_csv(output, 'error1.csv') # local testing\n",
    "        print(outputfolder + 'campaign_cardType_error.csv')\n",
    "#         s3_resource = boto3.resource('s3')\n",
    "#         s3_resource.Object(bucket, outputfolder + 'campaign_cardType_error.csv').put(Body=output.getvalue())\n",
    "    print(\"DONE - db2_cardtype_f_partition\")\n",
    "\n",
    "def db2_customer_f_partition(partitionData, db1, bucket = None, outputfolder = None):\n",
    "    output = io.StringIO()\n",
    "    errorExist = False\n",
    "    for row in partitionData:\n",
    "        if db1.conn is None or not db1.conn.is_connected():\n",
    "            db1.get_conn(dbType = 'mysql')\n",
    "        db1_cursor = db1.conn.cursor(buffered=True)\n",
    "        \n",
    "        row = row.asDict()\n",
    "        try: \n",
    "            mapping = {'email': row['email'], 'name': row['name'], 'phone_number': row['phone'], 'card_type_id': row['id'], 'card_type': row['card_type']}\n",
    "            # print(mapping)\n",
    "            if mapping[\"card_type_id\"] is None:\n",
    "                raise Exception (\"No card type ID detected!\")\n",
    "            db1_cursor.execute(\"\"\"SELECT * FROM customer where card_type_id=%(card_type_id)s AND name=%(name)s \"\"\", mapping)\n",
    "            # print(db1_cursor.rowcount, \"asd\")\n",
    "            if db1_cursor.rowcount > 0 :\n",
    "                db1_cursor.execute(\"\"\"UPDATE customer SET email=%(email)s, phone_number=%(phone_number)s WHERE card_type_id=%(card_type_id)s AND name=%(name)s\"\"\", mapping)\n",
    "            else:\n",
    "                db1_cursor.execute(\"\"\"INSERT INTO customer (email,name,phone_number,card_type_id) VALUES (%(email)s , %(name)s , %(phone_number)s, %(card_type_id)s)\"\"\", mapping )\n",
    "            db1.conn.commit()\n",
    "            csv.DictWriter(output, row.keys()).writerow(row)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            errorExist = True\n",
    "            csv.DictWriter(output, row.keys()).writerow(row)\n",
    "        # yield Row(**row)\n",
    "    db1.close_conn()\n",
    "    if errorExist:\n",
    "        write_to_csv(output, 'error1.csv') # local testing\n",
    "        print(outputfolder + 'campaign_customer_error.csv')\n",
    "#         s3_resource = boto3.resource('s3')\n",
    "#         s3_resource.Object(bucket, outputfolder + 'campaign_customer_error.csv').put(Body=output.getvalue())\n",
    "    print(\"DONE - db2_customer_f_partition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d88e7b8-4568-4d46-9cd0-92fc65dfd6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "REWARD_TYPE_MAPPING = {\"scis_shopping\": \"cashback\", \"scis_freedom\": \"points\", \"scis_platinummiles\": \"miles\", \"scis_premiummiles\": \"miles\"}\n",
    "# s3_path = args.get('S3PATH')\n",
    "TENANT = 'scis'\n",
    "# BUCKET = args.get('BUCKET')\n",
    "OUTPUTFOLDER = '.'\n",
    "# print(s3_path, TENANT, BUCKET, OUTPUTFOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a21c9a4-9716-4adc-b3d6-cf15c1bde41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_name, hostname = None, user = None, password = None, \n",
    "card_db1_c = DB_Connection(db_name = 'card_db', hostname = 'host.docker.internal', driver_type = \"mysql\", driver_port = 3306, user = 'root', password = 'admin') # any connection in the vpc\n",
    "campaign_db2_c = DB_Connection(db_name = 'campaign_db', hostname = 'host.docker.internal', driver_type = \"mysql\", driver_port = 3306, user = 'root', password = 'admin') # any connection in the vpc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20afc02b-1bde-489e-8403-b3ee8145be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_df = spark.read.format(\"csv\").option(\"header\", \"true\").load('./users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efa924dd-6407-49ab-9c00-7da8aeec24c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create name and tenant column in s3_df (set-up)\n",
    "s3_df = s3_df.drop(*[\"created_at\",\"card_pan\"])\n",
    "s3_df = s3_df.withColumn('name', concat(col(\"first_name\"), lit(\" \"), col(\"last_name\")))\n",
    "s3_df = s3_df.withColumn('TENANT', lit(TENANT))\n",
    "s3_df = s3_df.drop(*[\"first_name\",\"last_name\"])\n",
    "mapping_expr = create_map([lit(x) for x in chain(*REWARD_TYPE_MAPPING.items())])\n",
    "s3_df = s3_df.withColumn('REWARD_TYPE', mapping_expr[col(\"card_type\")] )\n",
    "\n",
    "# Setup dataframe to insert to the respective databases -4: CUSTOMER_db1_df, CARD_db1_df, CARDTYPE_db2_df, CUSTOMER_db2_df\n",
    "CUSTOMER_db1_df = s3_df.drop_duplicates(subset=['id', 'TENANT']).select([\"id\", \"email\", \"TENANT\"]) # .withColumn('isProcess', lit(0))\n",
    "CARD_db1_df = s3_df.drop_duplicates(subset=['card_id', 'TENANT']).select([\"card_id\", \"card_type\", \"REWARD_TYPE\", \"TENANT\", \"id\"]) #.withColumn('isProcess', lit(0))\n",
    "CARDTYPE_db2_df = s3_df.drop_duplicates(subset=['card_type', 'TENANT']).select([\"card_type\", \"TENANT\"])\n",
    "CUSTOMER_db2_df = s3_df.drop_duplicates(subset=['name', 'card_type']).select([\"email\", \"name\", \"phone\", \"card_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59a29cc2-eb94-40b0-9de0-c6dda27d82f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join foreign key to customer via card_type_id .option('driver', 'com.mysql.jdbc.Driver')\n",
    "db2_CARDTYPE_df = spark.read.format(\"jdbc\").option('driver', 'com.mysql.jdbc.Driver').option(\"url\", campaign_db2_c.jdbc_url).option(\"user\", campaign_db2_c.user).option(\"password\", campaign_db2_c.password).option(\"dbtable\", \"card_type\").load()\n",
    "\n",
    "db2_CARDTYPE_df = db2_CARDTYPE_df.withColumnRenamed(\"name\", \"name_cardType\")\n",
    "CUSTOMER_db2_df = CUSTOMER_db2_df.join(db2_CARDTYPE_df, CUSTOMER_db2_df.card_type ==  db2_CARDTYPE_df.name_cardType, \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "148d99d7-e474-4015-9ac4-2054edb7c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2995abe7-21cd-4a1e-8fbf-4840e022ac60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting to databases.... ERROR FOLDER: .\n",
      "Insert CARD DB, CUSTOMER TABLE!\n",
      "Insert CARD DB, CARD TABLE!\n",
      "Insert CAMPAIGN DB, cardtype TABLE!\n",
      "Insert CAMPAIGN DB, customer TABLE!\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print(f\"Inserting to databases.... ERROR FOLDER: {OUTPUTFOLDER}\")\n",
    "# Start Insertion for Card Database: card and customer table\n",
    "card_db1_c.conn = None\n",
    "CUSTOMER_db1_df.foreachPartition( partial(db1_customer_f_partition, db1=card_db1_c, bucket = BUCKET, outputfolder = OUTPUTFOLDER) )\n",
    "card_db1_c.close_conn()\n",
    "print(\"Insert CARD DB, CUSTOMER TABLE!\")\n",
    "\n",
    "card_db1_c.conn = None\n",
    "CARD_db1_df.foreachPartition( partial(db1_card_f_partition, db1=card_db1_c , bucket = BUCKET, outputfolder = OUTPUTFOLDER) )\n",
    "card_db1_c.close_conn()\n",
    "print(\"Insert CARD DB, CARD TABLE!\")\n",
    "\n",
    "# Start Insertion for Campaign Database: card and customer table\n",
    "campaign_db2_c.conn = None\n",
    "CARDTYPE_db2_df.foreachPartition( partial(db2_cardtype_f_partition, db1=campaign_db2_c, bucket = BUCKET, outputfolder = OUTPUTFOLDER) )\n",
    "campaign_db2_c.close_conn()\n",
    "print(\"Insert CAMPAIGN DB, cardtype TABLE!\")\n",
    "\n",
    "campaign_db2_c.conn = None\n",
    "CUSTOMER_db2_df.foreachPartition( partial(db2_customer_f_partition, db1=campaign_db2_c, bucket = BUCKET, outputfolder = OUTPUTFOLDER) )\n",
    "campaign_db2_c.close_conn()\n",
    "print(\"Insert CAMPAIGN DB, customer TABLE!\")\n",
    "\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951b5c5f-746d-48fa-ad56-7d269f5e1688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6077f4-5b50-411b-ae79-598ee70ab38d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa62cd05-260e-45fd-9241-355fd5e6b416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
